import tkinter as tk
from tkinter import filedialog, messagebox, ttk
from PIL import Image, ImageTk
import cv2
import numpy as np
import time
from collections import deque

# =============================================================================
# PH·∫¶N 1: C√ÅC H√ÄM X·ª¨ L√ù ·∫¢NH C·ªêT L√ïI (ƒê∆Ø·ª¢C C·∫¢I THI·ªÜN)
# =============================================================================

def load_image_grayscale(image_path):
    """T·∫£i ·∫£nh v√† chuy·ªÉn sang ·∫£nh x√°m."""
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError("Kh√¥ng th·ªÉ t·∫£i ·∫£nh. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n.")
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    return img, gray

def apply_gaussian_blur(gray_img, kernel_size=(5, 5)):
    """√Åp d·ª•ng l·ªçc Gaussian ƒë·ªÉ gi·∫£m nhi·ªÖu."""
    return cv2.GaussianBlur(gray_img, kernel_size, 0)

def apply_bilateral_filter(gray_img, d=9, sigma_color=75, sigma_space=75):
    """√Åp d·ª•ng bilateral filter - gi·ªØ c·∫°nh t·ªët h∆°n Gaussian."""
    return cv2.bilateralFilter(gray_img, d, sigma_color, sigma_space)

def sobel_detector(gray_img):
    """Ph√°t hi·ªán bi√™n b·∫±ng Sobel v·ªõi c·∫£i thi·ªán."""
    # L√†m m·ªù tr∆∞·ªõc ƒë·ªÉ gi·∫£m nhi·ªÖu
    blurred = apply_gaussian_blur(gray_img, (3, 3))
    
    # T√≠nh gradient
    grad_x = cv2.Sobel(blurred, cv2.CV_64F, 1, 0, ksize=3)
    grad_y = cv2.Sobel(blurred, cv2.CV_64F, 0, 1, ksize=3)
    
    # T√≠nh ƒë·ªô l·ªõn gradient
    magnitude = np.sqrt(grad_x**2 + grad_y**2)
    magnitude = np.uint8(np.clip(magnitude, 0, 255))
    
    return magnitude

def laplacian_detector(gray_img):
    """Ph√°t hi·ªán bi√™n b·∫±ng Laplacian v·ªõi c·∫£i thi·ªán."""
    # S·ª≠ d·ª•ng bilateral filter thay v√¨ Gaussian ƒë·ªÉ gi·ªØ c·∫°nh t·ªët h∆°n
    blurred_img = apply_bilateral_filter(gray_img)
    
    # √Åp d·ª•ng Laplacian
    lap = cv2.Laplacian(blurred_img, cv2.CV_64F, ksize=3)
    laplacian_result = cv2.convertScaleAbs(lap)
    
    # √Åp d·ª•ng threshold ƒë·ªÉ l√†m n·ªïi b·∫≠t c·∫°nh
    _, thresholded = cv2.threshold(laplacian_result, 30, 255, cv2.THRESH_BINARY)
    
    return thresholded

def canny_detector(gray_img, auto_threshold=True, t_lower=50, t_upper=150):
    """Ph√°t hi·ªán bi√™n b·∫±ng Canny v·ªõi auto threshold c·∫£i thi·ªán."""
    # L√†m m·ªù v·ªõi bilateral filter
    blurred_img = apply_bilateral_filter(gray_img)
    
    if auto_threshold:
        # S·ª≠ d·ª•ng ph∆∞∆°ng ph√°p Otsu ƒë·ªÉ t·ª± ƒë·ªông t√≠nh ng∆∞·ª°ng
        v = np.median(blurred_img)
        sigma = 0.33
        t_lower = int(max(0, (1.0 - sigma) * v))
        t_upper = int(min(255, (1.0 + sigma) * v))  # FIX: Thay ƒë·ªïi t·ª´ (1.0 - sigma) th√†nh (1.0 + sigma)
    
    edges = cv2.Canny(blurred_img, t_lower, t_upper)
    return edges

# =============================================================================
# PH·∫¶N 2: ·ª®NG D·ª§NG ƒê·∫æM V·∫¨T TH·ªÇ (ƒê∆Ø·ª¢C C·∫¢I THI·ªÜN)
# =============================================================================

def count_objects(original_img, gray_img, canny_t1, canny_t2, kernel_size, min_area, min_perimeter=0):
    """ƒê·∫øm v·∫≠t th·ªÉ v·ªõi nhi·ªÅu c·∫£i ti·∫øn."""
    # B∆∞·ªõc 1: L√†m m·ªù ƒë·ªÉ gi·∫£m nhi·ªÖu
    blurred = apply_bilateral_filter(gray_img)
    
    # B∆∞·ªõc 2: Ph√°t hi·ªán c·∫°nh b·∫±ng Canny
    canny_edges = cv2.Canny(blurred, canny_t1, canny_t2)
    
    # B∆∞·ªõc 3: Morphological operations ƒë·ªÉ ƒë√≥ng c√°c kho·∫£ng tr·ªëng
    k_size = int(kernel_size)
    if k_size % 2 == 0: 
        k_size += 1
    
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (k_size, k_size))
    
    # Dilate ƒë·ªÉ m·ªü r·ªông c·∫°nh
    dilated = cv2.dilate(canny_edges, kernel, iterations=2)
    
    # Close ƒë·ªÉ ƒë√≥ng c√°c l·ªó h·ªïng
    closed_edges = cv2.morphologyEx(dilated, cv2.MORPH_CLOSE, kernel, iterations=1)
    
    # Erode nh·∫π ƒë·ªÉ lo·∫°i b·ªè nhi·ªÖu nh·ªè
    closed_edges = cv2.erode(closed_edges, kernel, iterations=1)
    
    # B∆∞·ªõc 4: T√¨m contours
    contours, hierarchy = cv2.findContours(closed_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # B∆∞·ªõc 5: L·ªçc v√† ƒë·∫øm c√°c v·∫≠t th·ªÉ
    object_count = 0
    output_image = original_img.copy()
    valid_contours = []
    
    for cnt in contours:
        area = cv2.contourArea(cnt)
        perimeter = cv2.arcLength(cnt, True)
        
        # L·ªçc theo di·ªán t√≠ch v√† chu vi
        if area > min_area and perimeter > min_perimeter:
            # T√≠nh circularity ƒë·ªÉ lo·∫°i b·ªè nhi·ªÖu (h√¨nh qu√° d√†i, qu√° m√©o)
            if perimeter > 0:
                circularity = 4 * np.pi * area / (perimeter * perimeter)
                if circularity > 0.1:  # Ch·ªâ gi·ªØ l·∫°i c√°c h√¨nh kh√¥ng qu√° m√©o
                    object_count += 1
                    valid_contours.append(cnt)
                    
                    # V·∫Ω contour v√† s·ªë th·ª© t·ª±
                    cv2.drawContours(output_image, [cnt], -1, (0, 255, 0), 2)
                    
                    # T√≠nh centroid ƒë·ªÉ ƒë√°nh s·ªë
                    M = cv2.moments(cnt)
                    if M["m00"] != 0:
                        cX = int(M["m10"] / M["m00"])
                        cY = int(M["m01"] / M["m00"])
                        cv2.putText(output_image, str(object_count), (cX-10, cY+10), 
                                  cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
    
    # Hi·ªÉn th·ªã s·ªë l∆∞·ª£ng v·∫≠t th·ªÉ
    text = f"So luong vat the: {object_count}"
    cv2.putText(output_image, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
    
    return output_image, closed_edges, object_count

# =============================================================================
# PH·∫¶N 3: PH√ÅT HI·ªÜN L√ÄN ƒê∆Ø·ªúNG V·ªöI KALMAN FILTER
# =============================================================================

class LaneTracker:
    """Class ƒë·ªÉ theo d√µi l√†n ƒë∆∞·ªùng v·ªõi Kalman filter."""
    def __init__(self):
        self.left_fit_history = deque(maxlen=5)
        self.right_fit_history = deque(maxlen=5)
        
    def add_measurement(self, left_fit, right_fit):
        """Th√™m ƒëo ƒë·∫°c m·ªõi v√†o l·ªãch s·ª≠."""
        if left_fit is not None:
            self.left_fit_history.append(left_fit)
        if right_fit is not None:
            self.right_fit_history.append(right_fit)
    
    def get_smoothed_fit(self):
        """L·∫•y k·∫øt qu·∫£ l√†m m∆∞·ª£t t·ª´ l·ªãch s·ª≠."""
        left_avg = np.mean(self.left_fit_history, axis=0) if len(self.left_fit_history) > 0 else None
        right_avg = np.mean(self.right_fit_history, axis=0) if len(self.right_fit_history) > 0 else None
        return left_avg, right_avg

def lane_detect_edges(frame):
    """Ph√°t hi·ªán c·∫°nh cho l√†n ƒë∆∞·ªùng."""
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    
    # S·ª≠ d·ª•ng CLAHE ƒë·ªÉ c·∫£i thi·ªán ƒë·ªô t∆∞∆°ng ph·∫£n
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    enhanced = clahe.apply(gray)
    
    blur = cv2.GaussianBlur(enhanced, (5, 5), 0)
    canny = cv2.Canny(blur, 50, 150)
    return canny

def lane_create_mask(frame_edges, frame_shape):
    """T·∫°o mask v√πng quan t√¢m."""
    height, width = frame_shape
    polygons = np.array([
        [
            (int(width * 0.1), height),
            (int(width * 0.9), height),
            (int(width * 0.55), int(height * 0.6)),
            (int(width * 0.45), int(height * 0.6))
        ]
    ], dtype=np.int32)
    
    mask = np.zeros_like(frame_edges)
    cv2.fillPoly(mask, polygons, 255)
    masked_edges = cv2.bitwise_and(frame_edges, mask)
    return masked_edges

def lane_detect_lines(masked_edges):
    """Ph√°t hi·ªán c√°c ƒë∆∞·ªùng th·∫≥ng b·∫±ng Hough Transform."""
    lines = cv2.HoughLinesP(masked_edges, 2, np.pi/180, 50, 
                           minLineLength=40, maxLineGap=5)
    return lines

def lane_make_coordinates(frame, line_parameters):
    """T·∫°o t·ªça ƒë·ªô t·ª´ tham s·ªë ƒë∆∞·ªùng th·∫≥ng."""
    if line_parameters is None or len(line_parameters) != 2:
        return None
    
    slope, intercept = line_parameters
    
    # Tr√°nh chia cho 0
    if abs(slope) < 0.01:
        return None
    
    height = frame.shape[0]
    y1 = height
    y2 = int(height * 0.6)
    
    try:
        x1 = int((y1 - intercept) / slope)
        x2 = int((y2 - intercept) / slope)
        
        # Ki·ªÉm tra t·ªça ƒë·ªô c√≥ h·ª£p l·ªá kh√¥ng
        if x1 < 0 or x1 > frame.shape[1] or x2 < 0 or x2 > frame.shape[1]:
            return None
            
        return np.array([x1, y1, x2, y2])
    except:
        return None

def lane_average_slope_intercept(frame, lines):
    """T√≠nh trung b√¨nh slope v√† intercept cho c√°c l√†n ƒë∆∞·ªùng."""
    left_fit = []
    right_fit = []
    
    if lines is None: 
        return None, None, None
    
    for line in lines:
        x1, y1, x2, y2 = line.reshape(4)
        
        # Tr√°nh chia cho 0
        if x1 == x2: 
            continue
            
        parameters = np.polyfit((x1, x2), (y1, y2), 1)
        slope = parameters[0]
        intercept = parameters[1]
        
        # Ph√¢n lo·∫°i l√†n tr√°i v√† ph·∫£i d·ª±a tr√™n slope
        if slope < -0.5:  # L√†n tr√°i
            left_fit.append((slope, intercept))
        elif slope > 0.5:  # L√†n ph·∫£i
            right_fit.append((slope, intercept))
    
    # T√≠nh trung b√¨nh
    left_fit_avg = np.average(left_fit, axis=0) if len(left_fit) > 0 else None
    right_fit_avg = np.average(right_fit, axis=0) if len(right_fit) > 0 else None
    
    # T·∫°o t·ªça ƒë·ªô t·ª´ tham s·ªë trung b√¨nh
    left_line = lane_make_coordinates(frame, left_fit_avg) if left_fit_avg is not None else None
    right_line = lane_make_coordinates(frame, right_fit_avg) if right_fit_avg is not None else None
    
    return [left_line, right_line], left_fit_avg, right_fit_avg

def lane_display_lines(frame, lines, color=(0, 255, 0), thickness=10):
    """V·∫Ω c√°c ƒë∆∞·ªùng l√†n l√™n frame."""
    line_image = np.zeros_like(frame)
    if lines is not None:
        for line in lines:
            if line is not None:
                x1, y1, x2, y2 = line
                cv2.line(line_image, (x1, y1), (x2, y2), color, thickness)
    return line_image

def lane_calculate_steering(frame, left_params, right_params):
    """T√≠nh to√°n h∆∞·ªõng l√°i."""
    if left_params is None or right_params is None: 
        return "Lane Not Found", 0
    
    height, width = frame.shape[:2]
    car_center_x = width // 2
    
    try:
        left_x_bottom = int((height - left_params[1]) / left_params[0])
        right_x_bottom = int((height - right_params[1]) / right_params[0])
        lane_center_x = (left_x_bottom + right_x_bottom) / 2
        offset = car_center_x - lane_center_x
        
        # T√≠nh g√≥c l√°i d·ª±a tr√™n offset
        if offset > 30:
            command = "Steer Left"
        elif offset < -30:
            command = "Steer Right"
        else:
            command = "Straight"
        
        return command, offset
    except:
        return "Error", 0

def lane_display_info(frame, command, offset):
    """Hi·ªÉn th·ªã th√¥ng tin l√°i."""
    color = (0, 255, 0) if command == "Straight" else (0, 255, 255)
    cv2.putText(frame, command, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 
               1, color, 2, cv2.LINE_AA)
    cv2.putText(frame, f"Offset: {offset:.2f} px", (50, 100), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)
    return frame

def lane_process_pipeline(frame, tracker=None):
    """Pipeline x·ª≠ l√Ω ph√°t hi·ªán l√†n ƒë∆∞·ªùng."""
    original_frame = frame.copy()
    
    # Ph√°t hi·ªán c·∫°nh
    canny_edges = lane_detect_edges(frame)
    
    # T·∫°o mask
    masked_canny = lane_create_mask(canny_edges, frame.shape[:2])
    
    # Ph√°t hi·ªán ƒë∆∞·ªùng th·∫≥ng
    lines = lane_detect_lines(masked_canny)
    
    # T√≠nh trung b√¨nh slope v√† intercept
    averaged_lines, left_params, right_params = lane_average_slope_intercept(original_frame, lines)
    
    # S·ª≠ d·ª•ng tracker n·∫øu c√≥
    if tracker is not None:
        tracker.add_measurement(left_params, right_params)
        left_params_smooth, right_params_smooth = tracker.get_smoothed_fit()
        
        # T·∫°o l·∫°i ƒë∆∞·ªùng t·ª´ tham s·ªë l√†m m∆∞·ª£t
        if left_params_smooth is not None:
            left_line_smooth = lane_make_coordinates(original_frame, left_params_smooth)
        else:
            left_line_smooth = None
            
        if right_params_smooth is not None:
            right_line_smooth = lane_make_coordinates(original_frame, right_params_smooth)
        else:
            right_line_smooth = None
        
        averaged_lines = [left_line_smooth, right_line_smooth]
        left_params = left_params_smooth
        right_params = right_params_smooth
    
    # T√≠nh h∆∞·ªõng l√°i
    steering_command, offset = lane_calculate_steering(original_frame, left_params, right_params)
    
    # V·∫Ω c√°c ƒë∆∞·ªùng ph√°t hi·ªán ƒë∆∞·ª£c
    line_image = lane_display_lines(original_frame, averaged_lines, (0, 0, 255), 10)
    
    # K·∫øt h·ª£p v·ªõi ·∫£nh g·ªëc
    combo_image = cv2.addWeighted(original_frame, 0.8, line_image, 1, 0)
    
    # Hi·ªÉn th·ªã th√¥ng tin
    final_image = lane_display_info(combo_image, steering_command, offset)
    
    return final_image

# =============================================================================
# PH·∫¶N 4: GIAO DI·ªÜN NG∆Ø·ªúI D√ôNG (GUI) - HO√ÄN THI·ªÜN
# =============================================================================

class EdgeDetectionApp:
    def __init__(self, root):
        self.root = root
        self.root.title("·ª®ng d·ª•ng X·ª≠ l√Ω ·∫£nh N√¢ng cao - Edge Detection & Lane Finding")
        self.root.geometry("1500x900")

        self.original_img = None
        self.gray_img = None
        self.processed_img = None
        self.image_path = None
        self.video_running = False
        self.cap = None
        self.lane_tracker = None

        # --- Layout ch√≠nh ---
        frame_controls = tk.Frame(root, width=320, bg='#f0f0f0', relief=tk.RIDGE, borderwidth=2)
        frame_controls.pack(side=tk.LEFT, fill=tk.Y)
        frame_controls.pack_propagate(False)

        frame_images = tk.Frame(root, bg='white')
        frame_images.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True)

        # --- Panels hi·ªÉn th·ªã ·∫£nh ---
        self.panel_original = tk.Label(frame_images, bg='white', text="·∫¢nh g·ªëc", 
                                      font=("Arial", 12, "bold"), compound='top')
        self.panel_original.pack(side=tk.LEFT, padx=10, pady=10, expand=True)
        
        self.panel_processed = tk.Label(frame_images, bg='white', text="·∫¢nh x·ª≠ l√Ω", 
                                       font=("Arial", 12, "bold"), compound='top')
        self.panel_processed.pack(side=tk.RIGHT, padx=10, pady=10, expand=True)

        # --- CONTROLS: PH·∫¶N ·∫¢NH Tƒ®NH ---
        lbl_title = tk.Label(frame_controls, text="üì∑ ·∫¢NH Tƒ®NH", 
                           font=("Arial", 14, "bold"), bg='#f0f0f0', fg='#2c3e50')
        lbl_title.pack(pady=(15, 10), padx=10)

        btn_style = {'font': ('Arial', 10), 'bg': '#3498db', 'fg': 'white', 
                    'activebackground': '#2980b9', 'cursor': 'hand2'}

        tk.Button(frame_controls, text="üìÇ T·∫£i ·∫£nh", command=self.load_image, 
                 **btn_style).pack(fill=tk.X, padx=10, pady=3)
        
        tk.Button(frame_controls, text="üîç Sobel Detector", command=self.run_sobel, 
                 **btn_style).pack(fill=tk.X, padx=10, pady=3)
        
        tk.Button(frame_controls, text="üîç Laplacian Detector", command=self.run_laplacian, 
                 **btn_style).pack(fill=tk.X, padx=10, pady=3)
        
        tk.Button(frame_controls, text="üîç Canny Detector (Auto)", command=self.run_canny, 
                 **btn_style).pack(fill=tk.X, padx=10, pady=3)

        # --- Ph·∫ßn tinh ch·ªânh ƒë·∫øm v·∫≠t th·ªÉ ---
        separator = ttk.Separator(frame_controls, orient='horizontal')
        separator.pack(fill=tk.X, padx=10, pady=15)

        tk.Label(frame_controls, text="‚öôÔ∏è TINH CH·ªàNH ƒê·∫æM", 
                font=("Arial", 12, "bold"), bg='#f0f0f0', fg='#2c3e50').pack(pady=(5, 10), padx=10)

        # Canny T1
        tk.Label(frame_controls, text="Ng∆∞·ª°ng Canny T1:", bg='#f0f0f0', 
                font=('Arial', 9)).pack(padx=10, anchor='w')
        self.slider_t1 = tk.Scale(frame_controls, from_=0, to=255, orient=tk.HORIZONTAL, 
                                 bg='#f0f0f0', highlightthickness=0, 
                                 troughcolor='#3498db', sliderlength=20)
        self.slider_t1.set(50)
        self.slider_t1.pack(fill=tk.X, padx=10)
        
        # Canny T2
        tk.Label(frame_controls, text="Ng∆∞·ª°ng Canny T2:", bg='#f0f0f0', 
                font=('Arial', 9)).pack(padx=10, anchor='w')
        self.slider_t2 = tk.Scale(frame_controls, from_=0, to=255, orient=tk.HORIZONTAL, 
                                 bg='#f0f0f0', highlightthickness=0,
                                 troughcolor='#3498db', sliderlength=20)
        self.slider_t2.set(150)
        self.slider_t2.pack(fill=tk.X, padx=10)

        # Kernel Size
        tk.Label(frame_controls, text="K√≠ch th∆∞·ªõc Kernel:", bg='#f0f0f0', 
                font=('Arial', 9)).pack(padx=10, anchor='w')
        self.slider_kernel = tk.Scale(frame_controls, from_=1, to=21, orient=tk.HORIZONTAL, 
                                     bg='#f0f0f0', highlightthickness=0,
                                     troughcolor='#e74c3c', sliderlength=20)
        self.slider_kernel.set(5)
        self.slider_kernel.pack(fill=tk.X, padx=10)

        # Min Area
        tk.Label(frame_controls, text="Di·ªán t√≠ch t·ªëi thi·ªÉu:", bg='#f0f0f0', 
                font=('Arial', 9)).pack(padx=10, anchor='w')
        self.slider_area = tk.Scale(frame_controls, from_=0, to=2000, orient=tk.HORIZONTAL, 
                                   bg='#f0f0f0', highlightthickness=0,
                                   troughcolor='#27ae60', sliderlength=20)
        self.slider_area.set(100)
        self.slider_area.pack(fill=tk.X, padx=10)

        tk.Button(frame_controls, text="üî¢ ƒê·∫øm V·∫≠t th·ªÉ", command=self.run_counting, 
                 bg='#e67e22', fg='white', font=('Arial', 11, 'bold'), 
                 activebackground='#d35400', cursor='hand2').pack(fill=tk.X, padx=10, pady=8)

        # --- PH·∫¶N VIDEO ---
        separator2 = ttk.Separator(frame_controls, orient='horizontal')
        separator2.pack(fill=tk.X, padx=10, pady=15)

        lbl_video = tk.Label(frame_controls, text="üé• VIDEO", 
                           font=("Arial", 14, "bold"), bg='#f0f0f0', fg='#2c3e50')
        lbl_video.pack(pady=(5, 10), padx=10)

        self.btn_lane = tk.Button(frame_controls, text="üõ£Ô∏è Ph√°t hi·ªán l√†n ƒë∆∞·ªùng", 
                                  command=self.run_lane_detection_video, 
                                  bg='#27ae60', fg='white', font=("Arial", 11, "bold"),
                                  activebackground='#229954', cursor='hand2')
        self.btn_lane.pack(fill=tk.X, padx=10, pady=5)

        self.btn_stop_video = tk.Button(frame_controls, text="‚èπÔ∏è D·ª´ng Video", 
                                        command=self.stop_video, state=tk.DISABLED,
                                        bg='#e74c3c', fg='white', font=("Arial", 10, "bold"),
                                        activebackground='#c0392b', cursor='hand2')
        self.btn_stop_video.pack(fill=tk.X, padx=10, pady=3)

        # --- N√∫t l∆∞u ---
        tk.Button(frame_controls, text="üíæ L∆∞u ·∫£nh k·∫øt qu·∫£", command=self.save_image,
                 bg='#9b59b6', fg='white', font=('Arial', 10, 'bold'),
                 activebackground='#8e44ad', cursor='hand2').pack(fill=tk.X, padx=10, 
                                                                   pady=(20, 15), side=tk.BOTTOM)

        # Status bar
        self.status_bar = tk.Label(root, text="S·∫µn s√†ng", bd=1, relief=tk.SUNKEN, 
                                  anchor=tk.W, bg='#ecf0f1', font=('Arial', 9))
        self.status_bar.pack(side=tk.BOTTOM, fill=tk.X)

    # --- C√ÅC H√ÄM X·ª¨ L√ù ·∫¢NH Tƒ®NH ---
    def load_image(self):
        """T·∫£i ·∫£nh t·ª´ file."""
        self.image_path = filedialog.askopenfilename(
            title="Ch·ªçn ·∫£nh",
            filetypes=[("Image files", "*.jpg *.jpeg *.png *.bmp *.tiff")])
        
        if not self.image_path: 
            return
        
        try:
            self.original_img, self.gray_img = load_image_grayscale(self.image_path)
            self.display_image(self.original_img, self.panel_original, "·∫¢nh g·ªëc")
            self.display_image(self.gray_img, self.panel_processed, "·∫¢nh x√°m")
            self.status_bar.config(text=f"ƒê√£ t·∫£i: {self.image_path}")
        except Exception as e: 
            messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ t·∫£i ·∫£nh: {e}")
            self.status_bar.config(text="L·ªói khi t·∫£i ·∫£nh")

    def run_sobel(self):
        """Ch·∫°y Sobel detector."""
        if self.gray_img is None: 
            return messagebox.showwarning("C·∫£nh b√°o", "Vui l√≤ng t·∫£i ·∫£nh tr∆∞·ªõc!")
        
        self.status_bar.config(text="ƒêang x·ª≠ l√Ω Sobel...")
        self.root.update()
        
        self.processed_img = sobel_detector(self.gray_img)
        self.display_image(self.processed_img, self.panel_processed, "K·∫øt qu·∫£ Sobel")
        self.status_bar.config(text="Ho√†n th√†nh Sobel detector")

    def run_laplacian(self):
        """Ch·∫°y Laplacian detector."""
        if self.gray_img is None: 
            return messagebox.showwarning("C·∫£nh b√°o", "Vui l√≤ng t·∫£i ·∫£nh tr∆∞·ªõc!")
        
        self.status_bar.config(text="ƒêang x·ª≠ l√Ω Laplacian...")
        self.root.update()
        
        self.processed_img = laplacian_detector(self.gray_img)
        self.display_image(self.processed_img, self.panel_processed, "K·∫øt qu·∫£ Laplacian")
        self.status_bar.config(text="Ho√†n th√†nh Laplacian detector")

    def run_canny(self):
        """Ch·∫°y Canny detector v·ªõi auto threshold."""
        if self.gray_img is None: 
            return messagebox.showwarning("C·∫£nh b√°o", "Vui l√≤ng t·∫£i ·∫£nh tr∆∞·ªõc!")
        
        self.status_bar.config(text="ƒêang x·ª≠ l√Ω Canny...")
        self.root.update()
        
        self.processed_img = canny_detector(self.gray_img, auto_threshold=True)
        self.display_image(self.processed_img, self.panel_processed, "K·∫øt qu·∫£ Canny (Auto)")
        self.status_bar.config(text="Ho√†n th√†nh Canny detector")

    def run_counting(self):
        """Ch·∫°y ƒë·∫øm v·∫≠t th·ªÉ."""
        if self.original_img is None: 
            return messagebox.showwarning("C·∫£nh b√°o", "Vui l√≤ng t·∫£i ·∫£nh tr∆∞·ªõc!")
        
        t1, t2 = self.slider_t1.get(), self.slider_t2.get()
        
        # ƒê·∫£m b·∫£o t2 > t1
        if t1 >= t2: 
            t2 = t1 + 1
            self.slider_t2.set(t2)
        
        self.status_bar.config(text="ƒêang ƒë·∫øm v·∫≠t th·ªÉ...")
        self.root.update()
        
        result_img, edges_img, count = count_objects(
            self.original_img, 
            self.gray_img, 
            t1, t2, 
            self.slider_kernel.get(), 
            self.slider_area.get()
        )
        
        self.processed_img = result_img
        self.display_image(self.processed_img, self.panel_processed, 
                         f"K·∫øt qu·∫£: {count} v·∫≠t th·ªÉ")
        self.status_bar.config(text=f"ƒê√£ ph√°t hi·ªán {count} v·∫≠t th·ªÉ")

    # --- X·ª¨ L√ù VIDEO ---
    def run_lane_detection_video(self):
        """M·ªü file video v√† ch·∫°y ph√°t hi·ªán l√†n ƒë∆∞·ªùng."""
        video_path = filedialog.askopenfilename(
            title="Ch·ªçn file video", 
            filetypes=[("Video files", "*.mp4 *.avi *.mov *.mkv")])
        
        if not video_path: 
            return

        self.cap = cv2.VideoCapture(video_path)
        
        if not self.cap.isOpened():
            messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ m·ªü video: {video_path}")
            return

        self.video_running = True
        self.lane_tracker = LaneTracker()
        self.btn_lane.config(state=tk.DISABLED)
        self.btn_stop_video.config(state=tk.NORMAL)
        
        messagebox.showinfo("H∆∞·ªõng d·∫´n", 
                          "Video s·∫Ω ch·∫°y trong c·ª≠a s·ªï m·ªõi.\n"
                          "Nh·∫•n 'q' tr√™n b√†n ph√≠m ho·∫∑c n√∫t 'D·ª´ng Video' ƒë·ªÉ tho√°t.")
        
        self.status_bar.config(text=f"ƒêang x·ª≠ l√Ω video: {video_path}")
        
        # Ch·∫°y video trong m·ªôt thread ri√™ng ƒë·ªÉ kh√¥ng block GUI
        self.process_video()

    def process_video(self):
        """X·ª≠ l√Ω video frame by frame."""
        prev_time = 0
        frame_count = 0
        
        while self.video_running and self.cap.isOpened():
            ret, frame = self.cap.read()
            
            if not ret:
                break
            
            frame_count += 1
            
            try:
                # X·ª≠ l√Ω frame v·ªõi lane detection pipeline
                processed_frame = lane_process_pipeline(frame, self.lane_tracker)
                
                # T√≠nh FPS
                curr_time = time.time()
                fps = 1 / (curr_time - prev_time) if (curr_time - prev_time) > 0 else 0
                prev_time = curr_time
                
                # Hi·ªÉn th·ªã th√¥ng tin
                cv2.putText(processed_frame, f"FPS: {fps:.1f}", (10, 150), 
                          cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
                cv2.putText(processed_frame, f"Frame: {frame_count}", (10, 180), 
                          cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
                
                # Hi·ªÉn th·ªã frame
                cv2.imshow("Phat hien lan duong (Nhan 'q' de thoat)", processed_frame)
                
                # C·∫≠p nh·∫≠t status bar
                if frame_count % 30 == 0:  # C·∫≠p nh·∫≠t m·ªói 30 frame
                    self.status_bar.config(text=f"ƒêang x·ª≠ l√Ω frame {frame_count}, FPS: {fps:.1f}")
                    self.root.update()
                
            except Exception as e:
                print(f"L·ªói x·ª≠ l√Ω frame {frame_count}: {e}")
                break
            
            # Ki·ªÉm tra ph√≠m 'q' ƒë·ªÉ tho√°t
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        # D·ªçn d·∫πp
        self.stop_video()

    def stop_video(self):
        """D·ª´ng video ƒëang ch·∫°y."""
        self.video_running = False
        
        if self.cap is not None:
            self.cap.release()
            self.cap = None
        
        cv2.destroyAllWindows()
        
        self.btn_lane.config(state=tk.NORMAL)
        self.btn_stop_video.config(state=tk.DISABLED)
        self.status_bar.config(text="ƒê√£ d·ª´ng video")

    def save_image(self):
        """L∆∞u ·∫£nh k·∫øt qu·∫£."""
        if self.processed_img is None: 
            return messagebox.showwarning("C·∫£nh b√°o", "Kh√¥ng c√≥ ·∫£nh k·∫øt qu·∫£ ƒë·ªÉ l∆∞u!")
        
        save_path = filedialog.asksaveasfilename(
            defaultextension=".png", 
            filetypes=[("PNG files", "*.png"), ("JPEG files", "*.jpg"), ("All files", "*.*")])
        
        if save_path:
            cv2.imwrite(save_path, self.processed_img)
            messagebox.showinfo("Th√†nh c√¥ng", f"ƒê√£ l∆∞u ·∫£nh t·∫°i:\n{save_path}")
            self.status_bar.config(text=f"ƒê√£ l∆∞u: {save_path}")

    def display_image(self, img, panel, title_text):
        """Hi·ªÉn th·ªã ·∫£nh l√™n panel v·ªõi scaling t·ª± ƒë·ªông."""
        max_width, max_height = 700, 750
        
        if img is None:
            return
        
        h, w = img.shape[:2]
        ratio = min(max_width / w, max_height / h)
        
        # Ch·ªâ resize n·∫øu ·∫£nh qu√° l·ªõn
        if ratio < 1:
            new_w, new_h = int(w * ratio), int(h * ratio)
            img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)
        
        # Chuy·ªÉn ƒë·ªïi sang RGB ƒë·ªÉ hi·ªÉn th·ªã
        if len(img.shape) == 3:
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        else:
            img_rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
        
        # Chuy·ªÉn sang PhotoImage
        img_pil = Image.fromarray(img_rgb)
        img_tk = ImageTk.PhotoImage(img_pil)
        
        # C·∫≠p nh·∫≠t panel
        panel.config(image=img_tk, text=title_text, 
                    font=("Arial", 12, "bold"), compound='top')
        panel.image = img_tk  # Gi·ªØ reference ƒë·ªÉ tr√°nh garbage collection

# =============================================================================
# CH·∫†Y ·ª®NG D·ª§NG
# =============================================================================

if __name__ == "__main__":
    root = tk.Tk()
    app = EdgeDetectionApp(root)
    root.mainloop()